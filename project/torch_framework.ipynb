{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rnqFSVUd-_fA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhtCl1G8-_fC"
   },
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GY38RjTT-_fC"
   },
   "outputs": [],
   "source": [
    "def extract_distinct_labels(group_labels):\n",
    "    '''\n",
    "    compute labels dictionary\n",
    "    {\n",
    "        'type 1': [sample_start_position_1, sample_end_position_1],\n",
    "        'type 2': [sample_start_position_2, sample_end_position_2],\n",
    "        ...\n",
    "    }\n",
    "    '''\n",
    "    all_labels = {}\n",
    "    for i, label in enumerate(group_labels):\n",
    "        if label not in all_labels:\n",
    "            all_labels[label] = [i]\n",
    "        if i == len(group_labels)-1 or group_labels[i+1] not in all_labels:\n",
    "            all_labels[label].append(i+1)\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TDcekBTh-_fC"
   },
   "outputs": [],
   "source": [
    "def calculate_centers_SRW(P, all_labels):\n",
    "    '''\n",
    "    compute group centers, adapted from SRW centroid() function\n",
    "    \n",
    "    return a tensor with group centroids\n",
    "    if we have k groups and n nodes, then C.shape = (k, n)\n",
    "    '''\n",
    "    C = torch.zeros(size=(len(all_labels), P.shape[1]), dtype=torch.float64)\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        start, end = all_labels[label]\n",
    "        C[count,:] = torch.sum(P[start: end, :], axis = 0) / (end - start)\n",
    "        count += 1\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WmMVKCuD-_fC"
   },
   "outputs": [],
   "source": [
    "def label_to_id(all_labels):\n",
    "    '''\n",
    "    mapping label string to id\n",
    "     {\n",
    "        'type 1': 0,\n",
    "        'type 2': 1,\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    label_id = {}\n",
    "    count = 0\n",
    "    for label in all_labels:\n",
    "        label_id[label] = count\n",
    "        count += 1\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JlZoMY6G-_fC"
   },
   "outputs": [],
   "source": [
    "def loss(lambda_value, params, beta, P, group_labels, all_labels, is_trained):\n",
    "    '''\n",
    "    This function computes loss function adapted from SRW cost_func_WMW()\n",
    "    '''\n",
    "    \n",
    "    '''l1 norm'''\n",
    "    loss_value = torch.tensor(0, dtype =torch.float64)\n",
    "    for param in params:\n",
    "        loss_value += lambda_value * torch.norm(param, p=2)\n",
    "    accuracy = 0.0\n",
    "\n",
    "    '''retrieve centers'''\n",
    "    C = calculate_centers_SRW(P, all_labels)\n",
    "    '''retrieve ids for group labels'''\n",
    "    label_id = label_to_id(all_labels)\n",
    "    \n",
    "    '''necessary intermediate value for computing loss'''\n",
    "    P_dot_CT = torch.matmul(P, C.T)\n",
    "    C_dot_CT = torch.matmul(C, C.T)\n",
    "    P_dot_PT = torch.matmul(P, P.T)\n",
    "    \n",
    "    '''simply copy from SRW cost_func_WMW()'''\n",
    "    for u in range(P.shape[0]):\n",
    "        x_u = torch.tensor(-2.0, dtype =torch.float64)\n",
    "        i = label_id[group_labels[u]]\n",
    "        start, end = all_labels[group_labels[u]]\n",
    "        group_sample = end - start\n",
    "        if is_trained == False:\n",
    "            coeff = max((group_sample / (group_sample - 1)) ** 2, 1.0)\n",
    "        else:\n",
    "            coeff = 1.0\n",
    "        dist_ui = coeff *(P_dot_PT[u,u] - 2 * P_dot_CT[u, i] + C_dot_CT[i,i])\n",
    "        for label in label_id:\n",
    "            if label != group_labels[u]:\n",
    "                j = label_id[label]\n",
    "                x_u_tmp = dist_ui -(P_dot_PT[u,u] - 2 * P_dot_CT[u,j] + C_dot_CT[j,j])\n",
    "                if x_u_tmp > x_u:\n",
    "                    x_u = x_u_tmp\n",
    "        '''if correctly classified, increase accuracy'''\n",
    "        if x_u < 0.0:\n",
    "            accuracy += 1.0\n",
    "        loss_value += 1. / (1+torch.exp(-x_u / beta))\n",
    "    return loss_value, accuracy / P.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zYPHI3V-_fC"
   },
   "source": [
    "## Model class implement with pytorch\n",
    "* train with simple gradient descent\n",
    "* add validation module \n",
    "* support MLP in activation module\n",
    "* support Sigmoid and ReLu activation in MLP\n",
    "* support Softplus and Gaussian activation in MLP\n",
    "* use torch.optim to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fRi30wDS-_fC"
   },
   "outputs": [],
   "source": [
    "class SRW_pytorch:\n",
    "    def __init__(self, n_iter, lambda_value, beta, features, edges, group_labels_train, P_train, group_labels_val, P_val, betas, layers, params, rst_prob, lr):\n",
    "        self.n_iter = n_iter #number of iterations for training'''\n",
    "        self.lambda_value = lambda_value #coefficient for regularization'''\n",
    "        self.beta = beta #parameter for loss function'''\n",
    "        self.features = features #features of training dataset'''\n",
    "        self.edges = edges #edges of training dataset'''\n",
    "        self.group_labels_train = group_labels_train #labels of training dataset'''\n",
    "        self.P_train = P_train #initialized P matrix'''\n",
    "        self.group_labels_val = group_labels_val #labels of training dataset'''\n",
    "        self.P_val = P_val #initialized P matrix'''\n",
    "        self.rst_prob = rst_prob #random walk reset probabilities'''\n",
    "        self.lr = lr #learning rate'''\n",
    "        self.params = params #params for MLP activation\n",
    "        self.layers = layers #layers for MLP \n",
    "        self.betas = betas # adam beta\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "    def train(self):\n",
    "        optimizer = torch.optim.Adam(self.params, lr=self.lr, betas = self.betas)\n",
    "        for t in range(n_iter):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            '''compute edge strength, through MLP activation'''\n",
    "            strength = self.activation()\n",
    "\n",
    "            '''create transition matrix Q'''\n",
    "            Q = torch.zeros(size=(self.P_train.shape[1], self.P_train.shape[1]), dtype = torch.float64)\n",
    "            for j in range(strength.shape[0]):\n",
    "                Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
    "\n",
    "            '''normalize Q'''\n",
    "            Q = Q / (torch.sum(Q, axis = 1) + self.eps).reshape(-1,1)\n",
    "            \n",
    "            '''noramlize P'''\n",
    "            P_init = self.P_train / (torch.sum(self.P_train, axis = 1) + self.eps).reshape(-1,1)\n",
    "\n",
    "            '''create P matrix for random walk'''\n",
    "            P = P_init.detach().clone()\n",
    "            \n",
    "            '''for test, only peform random walk 20 times''' \n",
    "            for j in range(20):\n",
    "                P = (1.0-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
    "\n",
    "            '''compute loss and backward()'''\n",
    "            all_labels = extract_distinct_labels(self.group_labels_train)\n",
    "            loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, self.group_labels_train, all_labels, False)\n",
    "            loss_value.backward()\n",
    "            \n",
    "            '''update parameters'''\n",
    "            optimizer.step()\n",
    "\n",
    "            print(\"[%d/%d] training loss: %.4f\\t training accuracy: %.4f\" %(t+1, n_iter, loss_value, accuracy))\n",
    "\n",
    "            loss_value_val, accuracy_val = self.validation()\n",
    "            print(\"[%d/%d] validation loss: %.4f\\t validation accuracy: %.4f\" %(t+1, n_iter, loss_value_val, accuracy_val))\n",
    "            \n",
    "            \n",
    "    \n",
    "    def activation(self):\n",
    "        strength = self.features\n",
    "        for i in range(len(self.layers)):\n",
    "            if self.layers[i] == 'sigmoid':\n",
    "                strength = 1.0 / (1.0 + torch.exp(-torch.matmul(strength, self.params[i])))\n",
    "            elif self.layers[i] == 'ReLu':\n",
    "                strength = torch.nn.functional.relu(torch.matmul(strength, self.params[i]))\n",
    "            elif self.layers[i] == 'softplus':\n",
    "                strength = torch.log(1.0 + torch.exp(torch.matmul(strength, self.params[i])))\n",
    "            elif self.layers[i] == 'gaussian':\n",
    "                strength = torch.exp(-torch.matmul(strength, self.params[i]) ** 2)\n",
    "            else:\n",
    "                raise NotImplementedError(\"%s layer has not implemented yet\" %(self.layer[i]))\n",
    "                \n",
    "        return strength\n",
    "        \n",
    "    def validation(self):\n",
    "        strength = self.activation()\n",
    "        \n",
    "        Q = torch.zeros(size=(self.P_val.shape[1], self.P_val.shape[1]), dtype =torch.float64)\n",
    "        for j in range(strength.shape[0]):\n",
    "            Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
    "        Q = Q / (torch.sum(Q, axis = 1) + self.eps).reshape(-1,1)\n",
    "        P_init = self.P_val / (torch.sum(self.P_val, axis = 1) + self.eps).reshape(-1,1)\n",
    "        P = P_init.detach().clone()\n",
    "        for j in range(20):\n",
    "            P = (1-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
    "        \n",
    "        all_labels = extract_distinct_labels(self.group_labels_val)\n",
    "        loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, self.group_labels_val, all_labels, False)\n",
    "        \n",
    "        return loss_value, accuracy\n",
    "    \n",
    "    def test(self, P_test, group_labels_test):\n",
    "        strength = self.activation()\n",
    "        \n",
    "        Q = torch.zeros(size=(P_test.shape[1], P_test.shape[1]), dtype =torch.float64)\n",
    "        for j in range(strength.shape[0]):\n",
    "            Q[self.edges[j][0], self.edges[j][1]] = strength[j, 0]\n",
    "        Q = Q / (torch.sum(Q, axis = 1) + self.eps).reshape(-1,1)\n",
    "        P_init = P_test / (torch.sum(P_test, axis = 1) + self.eps).reshape(-1,1)\n",
    "        P = P_init.detach().clone()\n",
    "        for j in range(20):\n",
    "            P = (1-self.rst_prob) * (torch.matmul(P,Q)) + self.rst_prob * P_init\n",
    "        \n",
    "        all_labels = extract_distinct_labels(group_labels_test)\n",
    "        loss_value, accuracy = loss(self.lambda_value, self.params, self.beta, P, group_labels_test, all_labels, False)\n",
    "        return loss_value, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXtcBZa5-_fC"
   },
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DCtK9VY9-_fC"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2R76W9Sx-_fC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SRW_v044 as SRW\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibAKJgzg-_fD"
   },
   "source": [
    "#### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUruAvJp-_fD",
    "outputId": "4a576410-7322-4b88-b58b-a9ca03c4902b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading network...\n",
      "\t- Nodes in adjacency matrix: 557\n",
      "\t- Nodes in adjacency matrix: 557\n"
     ]
    }
   ],
   "source": [
    "edges, features, node_names = SRW.load_network('data/BRCA_edge2features_2.txt')\n",
    "\n",
    "P_init_train, sample_names_train = SRW.load_samples('data/BRCA_training_data_2.txt', node_names)\n",
    "\n",
    "P_init_val, sample_names_val = SRW.load_samples('data/BRCA_validation_data_2.txt', node_names)\n",
    "\n",
    "group_labels_train = SRW.load_grouplabels('data/BRCA_training_lables_2.txt')\n",
    "\n",
    "group_labels_val = SRW.load_grouplabels('data/BRCA_validation_lables_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jKb4o2o-_fE"
   },
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hKO_FEQq-_fE"
   },
   "outputs": [],
   "source": [
    "def sort_argsort(seq):\n",
    "    argsort_seq = [i for (v, i) in sorted((v, i) for (i, v) in enumerate(seq))]\n",
    "    seq.sort()\n",
    "    return seq, argsort_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VuI1doD--_fE"
   },
   "outputs": [],
   "source": [
    "group_labels_train, group_labels_train_argsort = sort_argsort(group_labels_train)\n",
    "group_labels_val, group_labels_val_argsort = sort_argsort(group_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xp27oek--_fF"
   },
   "outputs": [],
   "source": [
    "P_init_train = P_init_train.toarray()[group_labels_train_argsort,:]\n",
    "P_init_val = P_init_val.toarray()[group_labels_val_argsort,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGFfGezU-_fF"
   },
   "source": [
    "#### initialize tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "urQnHX1P-_fF"
   },
   "outputs": [],
   "source": [
    "P_init_train = torch.tensor(P_init_train, requires_grad = True, dtype = torch.float64)\n",
    "features = torch.tensor(features.toarray(), requires_grad = True, dtype = torch.float64)\n",
    "P_init_val = torch.tensor(P_init_val, requires_grad = False, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmV4_72O-_fF"
   },
   "source": [
    "#### run framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FPByT1Ve-_fF"
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "lambda_value = 0.1\n",
    "beta = 2e-4\n",
    "adam_betas = (0.9, 0.999)\n",
    "rst_prob = 0.3\n",
    "lr = 1.0\n",
    "w1 = torch.normal(mean = 0, std = 1, size = (features.shape[1], features.shape[1] // 2), requires_grad = True, dtype = torch.float64)\n",
    "w2 = torch.normal(mean = 0, std = 1, size = (features.shape[1] // 2, 1), requires_grad = True, dtype = torch.float64)\n",
    "params = [w1, w2]\n",
    "layers = ['softplus', 'softplus']\n",
    "solver = SRW_pytorch(n_iter, lambda_value, beta, features, edges, group_labels_train, P_init_train, group_labels_val, P_init_val, adam_betas, layers, params, rst_prob, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fBlIQFv-_fF",
    "outputId": "57262e96-62d1-4c51-d239-5a42f749bb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] training loss: 265.2046\t training accuracy: 0.5546\n",
      "[1/10] validation loss: 135.9545\t validation accuracy: 0.5524\n",
      "[2/10] training loss: 264.3640\t training accuracy: 0.5615\n",
      "[2/10] validation loss: 138.6296\t validation accuracy: 0.5524\n",
      "[3/10] training loss: 260.5508\t training accuracy: 0.5754\n",
      "[3/10] validation loss: 135.9154\t validation accuracy: 0.5769\n",
      "[4/10] training loss: 258.2404\t training accuracy: 0.5823\n",
      "[4/10] validation loss: 148.8951\t validation accuracy: 0.5000\n",
      "[5/10] training loss: 280.5579\t training accuracy: 0.5390\n",
      "[5/10] validation loss: 137.7253\t validation accuracy: 0.5490\n",
      "[6/10] training loss: 265.5510\t training accuracy: 0.5650\n",
      "[6/10] validation loss: 13.1728\t validation accuracy: 1.0000\n",
      "[7/10] training loss: 13.1728\t training accuracy: 1.0000\n",
      "[7/10] validation loss: 13.8063\t validation accuracy: 1.0000\n",
      "[8/10] training loss: 13.8063\t training accuracy: 1.0000\n",
      "[8/10] validation loss: 14.3281\t validation accuracy: 1.0000\n",
      "[9/10] training loss: 14.3281\t training accuracy: 1.0000\n",
      "[9/10] validation loss: 14.7453\t validation accuracy: 1.0000\n",
      "[10/10] training loss: 14.7453\t training accuracy: 1.0000\n",
      "[10/10] validation loss: 15.0705\t validation accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdMLvEqfzjN7"
   },
   "source": [
    "## Lung data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a85MRK0szi6O",
    "outputId": "8e657624-217a-4755-98a2-ab99622964c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading network...\n",
      "\t- Nodes in adjacency matrix: 441\n",
      "\t- Nodes in adjacency matrix: 441\n",
      "\t- Nodes in adjacency matrix: 441\n"
     ]
    }
   ],
   "source": [
    "edges, features, node_names = SRW.load_network('lung_data/lung_edge2features_2.txt')\n",
    "P_init_train, sample_names_train = SRW.load_samples('lung_data/lung_training_data_2.txt', node_names)\n",
    "P_init_val, sample_names_val = SRW.load_samples('lung_data/lung_validation_data_2.txt', node_names)\n",
    "P_init_test, sample_names_test = SRW.load_samples('lung_data/lung_testing_data_2.txt', node_names)\n",
    "group_labels_train = SRW.load_grouplabels('lung_data/lung_training_lables_2.txt')\n",
    "group_labels_val = SRW.load_grouplabels('lung_data/lung_validation_lables_2.txt')\n",
    "group_labels_test = SRW.load_grouplabels('lung_data/lung_testing_lables_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "z0vU8hSQ1ASc"
   },
   "outputs": [],
   "source": [
    "group_labels_train, group_labels_train_argsort = sort_argsort(group_labels_train)\n",
    "group_labels_val, group_labels_val_argsort = sort_argsort(group_labels_val)\n",
    "group_labels_test, group_labels_test_argsort = sort_argsort(group_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EqBFpgih1D7Q"
   },
   "outputs": [],
   "source": [
    "P_init_train = P_init_train.toarray()[group_labels_train_argsort,:]\n",
    "P_init_val = P_init_val.toarray()[group_labels_val_argsort,:]\n",
    "P_init_test = P_init_test.toarray()[group_labels_test_argsort,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "84NEWIED1MmQ"
   },
   "outputs": [],
   "source": [
    "features = torch.tensor(features.toarray(), requires_grad = True, dtype = torch.float64)\n",
    "P_init_train = torch.tensor(P_init_train, requires_grad = True, dtype = torch.float64)\n",
    "P_init_val = torch.tensor(P_init_val, requires_grad = False, dtype = torch.float64)\n",
    "P_init_test = torch.tensor(P_init_test, requires_grad = False, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eHJYLNhv1Exo"
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "lambda_value = 0.1\n",
    "beta = 2e-4\n",
    "adam_betas = (0.9, 0.999)\n",
    "rst_prob = 0.3\n",
    "lr = 1.0\n",
    "w1 = torch.normal(mean = 0, std = 1, size = (features.shape[1], features.shape[1] // 2), requires_grad = True, dtype = torch.float64)\n",
    "w2 = torch.normal(mean = 0, std = 1, size = (features.shape[1] // 2, 1), requires_grad = True, dtype = torch.float64)\n",
    "params = [w1, w2]\n",
    "layers = ['softplus', 'softplus']\n",
    "solver = SRW_pytorch(n_iter, lambda_value, beta, features, edges, group_labels_train, P_init_train, group_labels_val, P_init_val, adam_betas, layers, params, rst_prob, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCWBqHew1ICE",
    "outputId": "9eeb16e9-f3d5-4849-d1fd-0814d887157b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] training loss: 77.9222\t training accuracy: 0.5172\n",
      "[1/10] validation loss: 29.5850\t validation accuracy: 0.3429\n",
      "[2/10] training loss: 77.7418\t training accuracy: 0.5172\n",
      "[2/10] validation loss: 27.7609\t validation accuracy: 0.4571\n",
      "[3/10] training loss: 76.4790\t training accuracy: 0.5241\n",
      "[3/10] validation loss: 27.5109\t validation accuracy: 0.5143\n",
      "[4/10] training loss: 80.6495\t training accuracy: 0.5103\n",
      "[4/10] validation loss: 31.0402\t validation accuracy: 0.4286\n",
      "[5/10] training loss: 86.8053\t training accuracy: 0.5241\n",
      "[5/10] validation loss: 31.9661\t validation accuracy: 0.5429\n",
      "[6/10] training loss: 85.7731\t training accuracy: 0.5172\n",
      "[6/10] validation loss: 33.3624\t validation accuracy: 0.4857\n",
      "[7/10] training loss: 87.1587\t training accuracy: 0.4966\n",
      "[7/10] validation loss: 35.6264\t validation accuracy: 0.4286\n",
      "[8/10] training loss: 89.9011\t training accuracy: 0.4897\n",
      "[8/10] validation loss: 36.2861\t validation accuracy: 0.4000\n",
      "[9/10] training loss: 88.6274\t training accuracy: 0.5103\n",
      "[9/10] validation loss: 16.3200\t validation accuracy: 1.0000\n",
      "[10/10] training loss: 16.3200\t training accuracy: 1.0000\n",
      "[10/10] validation loss: 16.8955\t validation accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RUrtEIe1Ib_",
    "outputId": "b4dce0ab-e2d0-471e-c6c3-1e8bb008b593"
   },
   "outputs": [],
   "source": [
    "loss_test, accuracy_test = solver.test(P_init_test, group_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Hyab1nye2iLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 16.8955\t test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss: %.4f\\t test accuracy: %.4f\" %(loss_test, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "torch_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
